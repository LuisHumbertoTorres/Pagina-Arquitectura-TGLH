<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>UNIDAD 4</title>
    <link rel="shortcut icon" href="logo.png" type="image/x-icon">
    <link rel="stylesheet" href="normalize.css">
    <link rel="stylesheet" href="estilos.css">
</head>
<body>
    <a name="inicio"></a>
    <header class="hero">
        <nav class="nav container">
            <div class="nav__logo">
                <h2 class="nav__title">Arquitectura de Computadoras.</h2>
            </div>

            <ul class="nav__link nav__link--menu">
                <li class="nav__items">
                    <a href="index.html" class="nav__links">Inicio</a>
                </li>
                <li class="nav__items">
                    <a href="#footer" class="nav__links">Acerca de</a>
                </li>
                <li class="nav__items">
                    <a href="#footer" class="nav__links">Contacto</a>
                </li>

                <img src="close.svg" class="nav__close">
            </ul>

            <div class="nav__menu">
                <img src="menu.svg" class="nav__img">
            </div>
        </nav>

        <section class="hero__container container">
            <ul class="nav_link2">
                <h1 class="hero__title">UNIDAD 4</h1>
                <a href="Unidad1.html" class="cta">UNIDAD 1
                    <span id="span1"></span>
                    <span id="span2"></span>
                    <span id="span3"></span>
                    <span id="span4"></span>
                </a>
                <a href="Unidad2.html" class="cta">UNIDAD 2
                    <span id="span1"></span>
                    <span id="span2"></span>
                    <span id="span3"></span>
                    <span id="span4"></span>
                </a>
                <br>
                <br>
                <a href="Unidad3.html" class="cta">UNIDAD 3
                    <span id="span1"></span>
                    <span id="span2"></span>
                    <span id="span3"></span>
                    <span id="span4"></span>
                </a>
                <a href="Unidad4.html" class="cta">UNIDAD 4
                    <span id="span1"></span>
                    <span id="span2"></span>
                    <span id="span3"></span>
                    <span id="span4"></span>
                </a>                  
            </ul>         
        </section>
    </header>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h2 class="subtitle">4.1-.Aspectos Básicos de la computación paralela.</h2>
                <p class="knowledge__paragraph">La computación paralela es una forma de cómputo en la que muchas
                    instrucciones se ejecutan simultáneamente, operando sobre el
                    principio de que problemas grandes, a menudo se pueden dividir en
                    unos más pequeños, que luego son resueltos simultáneamente (en
                    paralelo). Hay varias formas diferentes de computación paralela:
                    paralelismo a nivel de bit, paralelismo a nivel de instrucción,
                    paralelismo de datos y paralelismo de tareas. El paralelismo se ha
                    empleado durante muchos años, sobre todo en la computación de
                    altas prestaciones, pero el interés en ella ha crecido últimamente
                    debido a las limitaciones físicas que impiden el aumento de la
                    frecuencia. Como el consumo de energía y por consiguiente la
                    generación de calor de las computadoras constituye una
                    preocupación en los últimos años, la computación en paralelo se ha
                    convertido en el paradigma dominante en la arquitectura de
                    computadores, principalmente en forma de procesadores
                    multinúcleo.</p><br>
                <img src="u4.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph">Los programas informáticos paralelos son más difíciles de escribir
                    que los secuenciales, porque la concurrencia introduce nuevos tipos
                    de errores de software, siendo las condiciones de carrera los más
                    comunes. La comunicación y sincronización entre diferentes
                    subtareas son algunos de los mayores obstáculos para obtener un
                    buen rendimiento del programa paralelo. La máxima aceleración
                    posible de un programa como resultado de la paralelización se
                    conoce como la ley de Amdahl.</p><br>
                <p class="knowledge__paragraph"><strong>Ley de Amdahl y ley de Gustafson.</strong><br>
                    Idealmente, la aceleración a partir de la paralelización es lineal,
                    doblar el número de elementos de procesamiento debe reducir a la
                    mitad el tiempo de ejecución y doblarlo por segunda vez debe
                    nuevamente reducir el tiempo a la mitad. Sin embargo, muy pocos
                    algoritmos paralelos logran una aceleración óptima. La mayoría
                    tienen una aceleración casi lineal para un pequeño número de
                    elementos de procesamiento, y pasa a ser constante para un gran
                    número de elementos de procesamiento.</p><br>
                <p class="knowledge__paragraph">La aceleración potencial de un algoritmo en una plataforma de
                    cómputo en paralelo está dada por la ley de Amdahl, formulada
                    originalmente por Gene Amdahl en la década de 1960. Esta señala
                    que una pequeña porción del programa que no pueda paralelizarse
                    va a limitar la aceleración que se logra con la paralelización. Los
                    programas que resuelven problemas matemáticos o ingenieriles
                    típicamente consisten en varias partes paralelizables y varias no
                    paralelizables (secuenciales).</p><br>
                
            </div>
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Dependencias.</strong><br>
                    Entender la dependencia de datos es fundamental en la
                    implementación de algoritmos paralelos. Ningún programa puede
                    ejecutar más rápidamente que la cadena más larga de cálculos
                    dependientes (conocida como la ruta crítica), ya que los cálculos que
                    dependen de cálculos previos en la cadena deben ejecutarse en
                    orden. Sin embargo, la mayoría de los algoritmos no consisten sólo
                    de una larga cadena de cálculos dependientes; generalmente hay
                    oportunidades para ejecutar cálculos independientes en paralelo.</p><br>
                <p class="knowledge__paragraph">Sea Pi y Pj dos segmentos del programa. Las condiciones de
                    Bernstein describen cuando los dos segmentos son independientes y
                    pueden ejecutarse en paralelo. Para Pi, sean Ii todas las variables de entrada y Oi las variables de salida, y del mismo modo para Pj. Pi y Pj son independientes si satisfacen.</p><br>
                <img src="u41.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Condiciones de carrera, exclusión mutua, sincronización, y desaceleración paralela.</strong><br>
                    Las subtareas en un programa paralelo a menudo son llamadas hilos.
                    Algunas arquitecturas de computación paralela utilizan versiones
                    más pequeñas y ligeras de hilos conocidas como hebras, mientras
                    que otros utilizan versiones más grandes conocidos como procesos.
                    Sin embargo, «hilos» es generalmente aceptado como un término
                    genérico para las subtareas. Los hilos a menudo tendrán que
                    actualizar algunas variables que se comparten entre ellos. Las
                    instrucciones entre los dos programas pueden entrelazarse en
                    cualquier orden.</p><br>
                <p class="knowledge__paragraph">Las aplicaciones a menudo se clasifican según la frecuencia con que
                    sus subtareas se sincronizan o comunican entre sí. Una aplicación
                    muestra un paralelismo de grano fino si sus subtareas deben
                    comunicase muchas veces por segundo, se considera paralelismo de
                    grano grueso si no se comunican muchas veces por segundo, y es
                    vergonzosamente paralelo si nunca o casi nunca se tienen que
                    comunicar.</p><br>
                <p class="knowledge__paragraph"><strong>Multiple Instruction, Multiple Data (MIMD).</strong><br>
                    Hay múltiples unidades de procesamiento, en la cual cada una tiene
                    tanto instrucciones como información separada. Cada elemento
                    ejecuta una instrucción distinta en un elemento de información
                    distinto. Los elementos de proceso trabajan asíncronamente. Los
                    clusters son ejemplo son ejemplos del modelo MIMD.</p><br>
                <img src="u42.png" class="knowledge__img">
            </figure>
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo2">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.2-.Tipos de computación paralela.</h6>
                <p class="knowledge__paragraph"><strong>Paralelismo a nivel de bit.</strong><br>
                    Desde el advenimiento de la integración a gran escala (VLSI) como
                    tecnología de fabricación de chips de computadora en la década de
                    1970 hasta alrededor de 1986, la aceleración en la arquitectura de
                    computadores se lograba en gran medida duplicando el tamaño de la
                    palabra en la computadora, la cantidad de información que el
                    procesador puede manejar por ciclo. El aumento del tamaño de la
                    palabra reduce el número de instrucciones que el procesador debe
                    ejecutar para realizar una operación en variables cuyos tamaños son
                    mayores que la longitud de la palabra. Por ejemplo, cuando un
                    procesador de 8 bits debe sumar dos enteros de 16 bits, el
                    procesador primero debe adicionar los 8 bits de orden inferior de
                    cada número entero con la instrucción de adición, a continuación,
                    añadir los 8 bits de orden superior utilizando la instrucción de
                    adición con acarreo que tiene en cuenta el bit de acarreo de la
                    adición de orden inferior, en este caso un procesador de 8 bits
                    requiere dos instrucciones para completar una sola operación, en
                    donde un procesador de 16 bits necesita una sola instrucción para
                    poder completarla.</p><br>
                <img src="u43.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Paralelismo a nivel de instrucción.</strong><br>
                    Los procesadores modernos tienen ''pipeline'' de instrucciones de
                    varias etapas. Cada etapa en el pipeline corresponde a una acción
                    diferente que el procesador realiza en la instrucción correspondiente
                    a la etapa; un procesador con un pipeline de N etapas puede tener
                    hasta n instrucciones diferentes en diferentes etapas de finalización.
                    El ejemplo canónico de un procesador segmentado es un procesador
                    RISC, con cinco etapas: pedir instrucción, decodificar, ejecutar,
                    acceso a la memoria y escritura. El procesador Pentium 4 tenía un
                    pipeline de 35 etapas.</p><br>
                <img src="u44.png" class="knowledge__img">
            </div>  
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Paralelismo de datos.</strong><br>
                    El paralelismo de datos es el paralelismo inherente en programas
                    con ciclos, que se centra en la distribución de los datos entre los
                    diferentes nodos computacionales que deben tratarse en paralelo.
                    "La paralelización de ciclos conduce a menudo a secuencias
                    similares de operaciones —no necesariamente idénticas— o
                    funciones que se realizan en los elementos de una gran estructura de
                    datos". Muchas de las aplicaciones científicas y de ingeniería
                    muestran paralelismo de datos.</p><br>
                <p class="knowledge__paragraph">Una dependencia de terminación de ciclo es la dependencia de una
                    iteración de un ciclo en la salida de una o más iteraciones anteriores.
                    Las dependencias de terminación de ciclo evitan la paralelización de
                    ciclos.</p><br>
                <img src="u45.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Paralelismo de tareas.</strong><br>
                    Paralelismo de tareas es un paradigma de la programación
                    concurrente que consiste en asignar distintas tareas a cada uno de los
                    procesadores de un sistema de cómputo. En consecuencia, cada
                    procesador efectuará su propia secuencia de operaciones.</p><br>
                <p class="knowledge__paragraph">En su modo más general, el paralelismo de tareas se representa
                    mediante un grafo de tareas, el cual es subdividido en subgrafos que
                    son luego asignados a diferentes procesadores. De la forma como se
                    corte el grafo, depende la eficiencia de paralelismo resultante. La
                    partición y asignación óptima de un grafo de tareas para ejecución
                    concurrente es un problema NP-completo, por lo cual en la práctica
                    se dispone de métodos heurísticos aproximados para lograr una
                    asignación cercana a la óptima.</p><br>
                <img src="u46.png" class="knowledge__img"> 
            </figure>          
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.2.1-.Clasificación.</h6>
                <p class="knowledge__paragraph">Las computadoras paralelas se pueden clasificar de acuerdo con el
                    nivel en el que el hardware soporta paralelismo. Esta clasificación es
                    análoga a la distancia entre los nodos básicos de cómputo. Estos no
                    son excluyentes entre sí, por ejemplo, los grupos de
                    multiprocesadores simétricos son relativamente comunes.</p><br>
                <p class="knowledge__paragraph"><strong>Computación multinúcleo: </strong>
                    un procesador multinúcleo es un
                    procesador que incluye múltiples unidades de ejecución
                    (núcleos) en el mismo chip. Un procesador multinúcleo puede
                    ejecutar múltiples instrucciones por ciclo de secuencias de
                    instrucciones múltiples.</p><br>
                <p class="knowledge__paragraph"><strong>Multiprocesamiento simétrico: </strong>
                    un multiprocesador simétrico
                    (SMP) es un sistema computacional con múltiples
                    procesadores idénticos que comparten memoria y se conectan
                    a través de un bus. La contención del bus previene el escalado
                    de esta arquitectura.</p><br>
                <p class="knowledge__paragraph"><strong>Computación en clúster: </strong>
                    un clúster es un grupo de
                    ordenadores débilmente acoplados que trabajan en estrecha
                    colaboración, de modo que en algunos aspectos pueden
                    considerarse como un solo equipo.</p><br>
                <p class="knowledge__paragraph"><strong>Procesamiento paralelo masivo: </strong>
                    tienden a ser más grandes
                    que los clústeres, con «mucho más» de 100 procesadores. En
                    un MPP, cada CPU tiene su propia memoria y una copia del
                    sistema operativo y la aplicación.</p><br>
                <p class="knowledge__paragraph"><strong>Computación distribuida: </strong>
                    la computación distribuida es la
                    forma más distribuida de la computación paralela. Se hace uso
                    de ordenadores que se comunican a través de la Internet para
                    trabajar en un problema dado.</p>
            </div>
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Computadoras paralelas especializadas: </strong>
                    dentro de la
                    computación paralela, existen dispositivos paralelos
                    especializados que generan interés. Aunque no son específicos
                    para un dominio, tienden a ser aplicables sólo a unas pocas
                    clases de problemas paralelos.</p><br>
                <p class="knowledge__paragraph"><strong>Cómputo reconfigurable con arreglos de compuertas
                    programables: </strong>
                    el cómputo reconfigurable es el uso de un
                    arreglo de compuertas programables (FPGA) como
                    coprocesador de un ordenador de propósito general.</p><br>
                <p class="knowledge__paragraph"><strong>Cómputo de propósito general en unidades de
                    procesamiento gráfico (GPGPU): </strong>
                    es una tendencia
                    relativamente reciente en la investigación de ingeniería
                    informática. Los GPUs son co-procesadores que han sido
                    fuertemente optimizados para procesamiento de gráficos por
                    computadora.</p><br>
                <p class="knowledge__paragraph"><strong>Circuitos integrados de aplicación específica: </strong>
                    debido a que
                    un ASIC (por definición) es específico para una aplicación
                    dada, puede ser completamente optimizado para esa
                    aplicación. Como resultado, para una aplicación dada, un
                    ASIC tiende a superar a un ordenador de propósito general.</p><br>
                <p class="knowledge__paragraph"><strong>Procesadores vectoriales: </strong>
                    pueden ejecutar la misma
                    instrucción en grandes conjuntos de datos. Tienen operaciones
                    de alto nivel que trabajan sobre arreglos lineales de números o
                    vectores.</p>
            </figure>
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo2">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.2.2-.Arquitectura de computadores secuenciales.</h6>
                <p class="knowledge__paragraph">A diferencia de los sistemas combinacionales, en los sistemas
                    secuenciales, los valores de las salidas, en un momento dado, no
                    dependen exclusivamente de los valores de las entradas en dicho
                    momento, sino también dependen del estado anterior o estado
                    interno. El sistema secuencial más simple es el biestable, de los
                    cuales, el de tipo D (o cerrojo) es el más utilizado actualmente.</p><br>
                <p class="knowledge__paragraph">El sistema secuencial requiere de la utilización de un dispositivo de
                    memoria que pueda almacenar la historia pasada de sus entradas
                    (denominadas variables de estado) y le permita mantener su estado
                    durante algún tiempo, estos dispositivos de memoria pueden ser
                    sencillos como un simple retardador o celdas de memoria de tipo
                    DRAM, SRAM o multivibradores biestables también conocido
                    como Flip-Flop.</p><br>
                <p class="knowledge__paragraph"><strong>Tipos de sistemas secuenciales.</strong><br>
                    En este tipo de circuitos entra un factor que no se había considerado
                    en los circuitos combinacionales, dicho factor es el tiempo, según
                    como manejan el tiempo se pueden clasificar en: circuitos
                    secuenciales síncronos y circuitos secuenciales asíncronos.</p><br>
            </div>  
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Circuitos secuenciales asíncronos.</strong><br>
                    En circuitos secuenciales asíncronos los cambios de estados ocurren
                    al ritmo natural asociado a las compuertas lógicas utilizadas en su
                    implementación, lo que produce retardos en cascadas entre los
                    biestables del circuito, es decir no utilizan elementos especiales de
                    memoria, lo que puede ocasionar algunos problemas de
                    funcionamiento, ya que estos retardos naturales no están bajo el
                    control del diseñador y además no son idénticos en cada compuerta
                    lógica.</p><br>
                <p class="knowledge__paragraph"><strong>Circuitos secuenciales síncronos.</strong><br>
                    Los circuitos secuenciales síncronos solo permiten un cambio de
                    estado en los instantes marcados o autorizados por una señal de
                    sincronismo de tipo oscilatorio denominada reloj (cristal o circuito
                    capaz de producir una serie de pulsos regulares en el tiempo), lo que
                    soluciona los problemas que tienen los circuitos asíncronos
                    originados por cambios de estado no uniformes dentro del sistema o
                    circuito.</p><br>
            </figure>          
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->
    <section class="fondo">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.2.3-.Organización de direcciones de memoria.</h6>
                <p class="knowledge__paragraph">La memoria principal en un ordenador en paralelo puede ser
                    compartida —compartida entre todos los elementos de
                    procesamiento en un único espacio de direcciones—, o distribuida
                    —cada elemento de procesamiento tiene su propio espacio local de
                    direcciones—. El término memoria distribuida se refiere al hecho de
                    que la memoria se distribuye lógicamente, pero a menudo implica
                    que también se distribuyen físicamente. La memoria distribuida-
                    compartida y la virtualización de memoria combinan los dos
                    enfoques, donde el procesador tiene su propia memoria local y
                    permite acceso a la memoria de los procesadores que no son locales.
                    Los accesos a la memoria local suelen ser más rápidos que los
                    accesos a memoria no local.</p><br>
                <p class="knowledge__paragraph">Las arquitecturas de ordenador en las que cada elemento de la
                    memoria principal se puede acceder con igual latencia y ancho de
                    banda son conocidas como arquitecturas de acceso uniforme a
                    memoria (UMA). Típicamente, sólo se puede lograr con un sistema
                    de memoria compartida, donde la memoria no está distribuida
                    físicamente. Un sistema que no tiene esta propiedad se conoce como
                    arquitectura de acceso a memoria no uniforme (NUMA). Los
                    sistemas de memoria distribuidos tienen acceso no uniforme a la
                    memoria.</p><br>
            </div>
            <figure class="knowledge__picture">
                <img src="u47.png" class="knowledge__img">
            </figure>
        </div>
    </section>
<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo2">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h2 class="subtitle2">4.3-.Sistemas de memoria compartida (multiprocesadores).</h2>
                <p class="knowledge__paragraph">
                    <ul class="knowledge__paragraph">
                        <li>Todos los procesadores acceden a una memoria común.</li>
                        <li>La comunicación entre procesadores se hace a través de la
                            memoria.</li>
                        <li>Se necesitan primitivas de sincronismo para asegurar el
                            intercambio de datos.</li>
                    </ul>
                </p><br>
                <img src="u48.png" class="knowledge__img"><br>
            </div>  
            <figure class="knowledge__picture">
                <img src="u49.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Estructura de los multiprocesadores de memoria compartida.</strong><br>
                    La mayoría de los multiprocesadores comerciales son del tipo UMA
                    (Uniform Memory Access): todos los procesadores tienen igual
                    tiempo de acceso a la memoria compartida. En la arquitectura UMA
                    los procesadores se conectan a la memoria a través de un bus, una
                    red multietapa o un conmutador de barras cruzadas (red multietapa o
                    un conmutador de barras cruzadas (crossbar crossbar) y disponen de
                    su propia ) y disponen de su propia memoria caché. Los
                    procesadores tipo NUMA (Non Uniform Memory Access) presentan
                    tiempos de acceso a la memoria compartida que dependen de la
                    ubicación del elemento de proceso y la memoria.</p><br>
            </figure>          
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.3.1-.Redes de interconexión dinámica (indirecta).</h6>
                <p class="knowledge__paragraph"><strong>Conexión por bus compartido.</strong><br>
                    Es la organización más común en los computadores personales y
                    servidores.
                    El bus consta de líneas de dirección, datos y control para
                    implementar:</p><br>
                <p class="knowledge__paragraph">
                    <ul class="knowledge__paragraph">
                        <li>El protocolo de transferencias de datos con la memoria.</li>
                        <li>El arbitraje del acceso al bus cuando más de un procesador
                            compite por utilizarlo.</li>
                    </ul>
                </p><br>
                <p class="knowledge__paragraph">Los procesadores utilizan cachés locales para: <br>
                    <ul class="knowledge__paragraph">
                        <li>Reducir el tiempo medio de acceso a memoria, como en un
                            monoprocesador.</li>
                        <li>Disminuir la utilización del bus compartido.</li>
                    </ul>
                </p><br>
                <img src="u50.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Protocolos de transferencia de ciclo partido.</strong><br>
                    La operación de lectura se divide en dos transacciones no continuas
                    de acceso al bus. La primera es de petición de lectura que realiza el
                    máster (procesador) sobre el slave (memoria). Una vez realizada la
                    petición el máster abandona el bus. Cuando el slave dispone del dato
                    leído, inicia un ciclo de bus actuando como máster para enviar el
                    dato al antiguo máster, que ahora actúa como slave.</p><br>
            </div>
            <figure class="knowledge__picture">
                <img src="u51.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Protocolo de arbitraje distribuido.</strong><br>
                    La responsabilidad del arbitraje se distribuye por los diferentes
                    procesadores conectados al bus.</p><br>
                <img src="u52.png" class="knowledge__img"><br>
                <p class="knowledge__paragraph"><strong>Conexión por red multietapa.</strong><br>
                    <ul class="knowledge__paragraph">
                        <li>Representan una alternativa intermedia de conexión entre el
                            bus y el crossbar.</li>
                        <li>Es de menor complejidad que el crossbar pero mayor que el
                            bus simple.</li>
                        <li>La conectividad es mayor que la del bus simple pero menor
                            que la del crossbar.</li>
                        <li>Se compone de varias etapas alternativas de conmutadores
                            simples y redes de interconexión.</li>
                    </ul>
                </p><br>
                <img src="u53.png" class="knowledge__img"><br>
            </figure>
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo2">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h2 class="subtitle2">4.4-.Sistemas de memoria distribuida (multicomputadores).</h2>
                <p class="knowledge__paragraph">Cada procesador tiene su propia memoria y la comunicación se
                    realiza por intercambio explícito de mensajes a través de una red.</p><br>
                <p class="knowledge__paragraph"><strong>Ventajas: </strong><br>
                    <ul class="knowledge__paragraph">
                        <li>El número de nodos puede ir desde algunas decenas hasta
                            varios miles (o más).</li>
                        <li>La arquitectura de paso de mensajes tiene ventajas sobre la de
                            memoria compartida cuando el número de procesadores es
                            grande.</li>
                        <li>El número de canales físicos entre nodos suele oscilar entre
                            cuatro y ocho.</li>
                        <li>Esta arquitectura es directamente escalable y presenta un bajo
                            coste para sistemas grandes.</li>
                        <li>Un problema se especifica como un conjunto de procesos que
                            se comunican entre sí y que se hacen corresponder sobre la
                            estructura física de procesadores.</li>
                    </ul>
                </p><br>
            </div>  
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Desventajas: </strong><br>
                    <ul class="knowledge__paragraph">
                        <li>Se necesitan técnicas de sincronización para acceder a las
                            variables compartidas.</li>
                        <li>La contención en la memoria puede reducir significativamente
                            la velocidad.</li>
                        <li>No son fácilmente escalables a un gran número de
                            procesadores.</li>
                    </ul>
                </p><br>
                <img src="u54.png" class="knowledge__img"><br>
            </figure>          
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h6 class="subtitle3">4.4.1-.Redes de interconexión estáticas.</h6>
                <p class="knowledge__paragraph">Los multicomputadores utilizan redes estáticas con enlaces directos
                    entre nodos. Cuando un nodo recibe un mensaje lo procesa si viene
                    dirigido a dicho nodo. Si el mensaje no va dirigido al nodo receptor
                    lo reenvía a otro por alguno de sus enlaces de salida siguiendo un
                    protocolo de encaminamiento.</p><br>
                <img src="u55.png" class="knowledge__img"><br>
            </div>
            <figure class="knowledge__picture">
                <p class="knowledge__paragraph"><strong>Propiedades más significativas</strong><br>
                    <ul class="knowledge__paragraph">
                        <li><strong>Topología de la red: </strong>determina el patrón de interconexión
                            entre nodos.</li>
                        <li><strong>Diámetro de la red: </strong>distancia máxima de los caminos más
                            cortos entre dos nodos de la red.</li>
                        <li><strong>Latencia: </strong>retardo de tiempo en el peor caso para un mensaje
                            transferido a través de la red.</li>
                        <li><strong>Ancho de banda: </strong>Transferencia máxima de datos en
                            Mbytes/segundo.</li>
                        <li><strong>Escalabilidad: </strong>posibilidad de expansión modular de la red.</li>
                        <li><strong>Grado de un nodo: </strong>número de enlaces o canales que inciden
                            en el nodo.</li>
                        <li><strong>Algoritmo de encaminamiento: </strong>determina el camino que
                            debe seguir un mensaje desde el nodo emisor al nodo receptor.</li>
                    </ul>
                </p><br>
            </figure>
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->

    <section class="fondo2">
        <div class="knowledge__container container">
            <div class="knowledege__texts">
                <h2 class="footer__title">4.5-.Casos para estudio.</h2>
                <p class="knowledge__paragraph">Por numerosos motivos, el procesamiento distribuido se ha
                    convertido en un área de gran importancia e interés dentro de la
                    ciencia de la computación, produciendo profundas transformaciones
                    en las líneas de investigación y desarrollo.</p><br>
                <p class="knowledge__paragraph">Interesa realizar investigación en la especificación, transformación,
                    optimización y evaluación de algoritmos distribuidos y paralelos.
                    Esto incluye el diseño y desarrollo de sistemas paralelos, la
                    transformación de algoritmos secuenciales en paralelos, y las
                    métricas de evaluación de performance sobre distintas plataformas
                    de soporte (hardware y software). Más allá de las mejoras constantes
                    en las arquitecturas físicas de soporte, uno de los mayores desafíos
                    se centra en cómo aprovechar al máximo la potencia de las mismas.</p><br>
                <p class="knowledge__paragraph"><strong>Líneas de investigación y desarrollo.</strong><br>
                    <ul class="knowledge__paragraph">
                        <li>Paralelización de algoritmos secuenciales. Diseño y
                            optimización de algoritmos.</li>
                        <li>Arquitecturas multicore y multithreading en multicore.</li>
                        <li>Modelos de representación y predicción de performance de
                            algoritmos paralelos.</li>
                        <li>Mapping y scheduling de aplicaciones paralelas sobre distintas
                            arquitecturas multiprocesador.</li>
                        <li>Métricas del paralelismo. Speedup, eficiencia, rendimiento,
                            granularidad, superlinealidad.</li>
                        <li>Balance de carga estático y dinámico. Técnicas de balanceo de
                            carga.</li>
                        <li>Análisis de los problemas de migración y asignación óptima de
                            procesos y datos a procesadores.</li>
                    </ul>
                </p><br>
                <p class="knowledge__paragraph"></p>
            </div>  
            <figure class="knowledge__picture">
                <ul class="knowledge__paragraph">
                    <li>Patrones de diseño de algoritmos paralelos.</li>
                        <li>Escalabilidad de algoritmos paralelos en arquitecturas
                            multiprocesador distribuidas.</li>
                        <li>Implementación de soluciones sobre diferentes modelos de
                            arquitectura homogéneas y heterogéneas.</li>
                        <li>Laboratorios remotos para el acceso transparente a recursos de
                            cómputo paralelo.</li>
                </ul>
                <p class="knowledge__paragraph"><strong>Algunas Implementaciones con procesamiento paralelo.</strong><br>
                <strong>NVIDIA</strong><br>
                    <ul class="knowledge__paragraph">Capa física (physical layer):
                        <li>GPU PhysX.</li>
                        <li>CPU PhysX.</li>
                    </ul>
                    <ul class="knowledge__paragraph">Capa de gráficos (graphics layer):
                        <li>GPU DirectX Windows.</li>
                    </ul>
                </p><br>
                <p class="knowledge__paragraph">
                    <strong>Intel</strong><br>
                        <ul class="knowledge__paragraph">Capa física (physical layer):
                            <li>No GPU PhysX.</li>
                            <li>CPU Havok.</li>
                        </ul>
                        <ul class="knowledge__paragraph">Capa de gráficos (graphics layer):
                            <li>GPU DirectX Windows.</li>
                        </ul>
                    </p><br>
                <p class="knowledge__paragraph">
                    <strong>AMD</strong><br>
                        <ul class="knowledge__paragraph">Capa física (physical layer):
                            <li>No GPU PhysX.</li>
                            <li>CPU Havok.</li>
                        </ul>
                        <ul class="knowledge__paragraph">Capa de gráficos (graphics layer):
                            <li>GPU DirectX Windows.</li>
                        </ul>
                </p>
            </figure>          
        </div>
    </section>

<!---------------------------------- AQUI EMPIEZA EL SIGUIENTE TEMA DE LA UNIDAD 4---------------------------------->


    <footer class="footer">
        <section class="footer__container container">
            <nav class="nav nav--footer">
                <h2 class="footer__title">Arquitectura de Computadoras.</h2>

                <ul class="nav__link nav__link--footer">
                    <li class="nav__items">
                        <a href="index.html" class="nav__links">Inicio</a>
                    </li>
                    <li class="nav__items">
                        <a href="#acerca_de" class="nav__links">Acerca de</a>
                    </li>
                    <li class="nav__items">
                        <a href="#footer" class="nav__links">Contacto</a>
                    </li>
                </ul>            
            </nav>
            <div class="nav__link nav__link--footer">
                <img class="img" src="tecnm.png" alt="">
            </div> 
        </section>    

        <section class="footer__copy container">
            <div class="footer__social">
                <a href="https://www.facebook.com/profile.php?id=100005265767901" class="footer__icons"><img src="facebook.svg" class="footer__img"></a>
                <a href="https://www.instagram.com/luis_humbertot/" class="footer__icons"><img src="insta.svg" class="footer__img"></a>
                <a href="https://www.youtube.com/channel/UCkb2XOW86VSIt5lc0w6Pltw" class="footer__icons"><img src="youtube.svg" class="footer__img"></a>
            </div>

            <h3 class="footer__copyright">Derechos reservados &copy; Luis Humberto</h3>
        </section>
    </footer>

    <script src="slider.js"></script>
    <script src="menu.js"></script>
</body>
</html>